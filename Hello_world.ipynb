{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlishaKK/AI-learning/blob/main/Hello_world.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pq9r-8Q72W-L"
      },
      "source": [
        "**TASK 1**\n",
        "\n",
        "Building a Simple Chatbot with LangChain and Google Gemini Flash 2.0 in Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi6kEO036xbs"
      },
      "source": [
        "**Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46zEFO2a9FFd",
        "outputId": "a111d4dc-edbe-492d-bd26-6e20c5581685"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/111.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.9/111.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.5/411.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U -q google-genai langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1tktzU761t5"
      },
      "source": [
        "**Set up your API key**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "A1pkoyZb9Jm3"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1v0UDw2o69Na"
      },
      "source": [
        "Import all the necessary modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Yd1vs3cP8EmS"
      },
      "outputs": [],
      "source": [
        "from google import genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtUDgrUz7FBy"
      },
      "source": [
        "Initialize SDK client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HghvVpbU0Uap"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "client = genai.Client()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qa8RUdt7K7I"
      },
      "source": [
        "Multimodal Live API are a new capability introduced with the Gemini 2.0 model. It won't work with previous generation models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "27Fikag0xSaB"
      },
      "outputs": [],
      "source": [
        "MODEL: str = \"gemini-2.0-flash-exp\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-HidX0f7RQq"
      },
      "source": [
        "The simplest way to use the Live API is as a text-to-text chat interface, but it can do a lot more than this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDfslcyIOqgI",
        "outputId": "330f694e-cd0a-45ca-800d-6372c51eaf1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL, contents='What are neural networks, and how do they mimic the human brain?'\n",
        ")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJI5pmWB7fgj"
      },
      "source": [
        "The `while` loop allows continuous conversation by repeatedly prompting for user input and generating responses until an exit command is given."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bGC6U2vm5Tk8",
        "outputId": "3b673b51-263b-4933-b778-627f30b08fa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: hi\n",
            "Chatbot: Hi there! How can I help you today?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    # Get user input\n",
        "    user_input = input(\"You: \")\n",
        "\n",
        "    # Exit condition\n",
        "    if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
        "        print(\"Chatbot: Goodbye! Have a great day!\")\n",
        "        break\n",
        "\n",
        "    # Generate response using the AI model\n",
        "    response = client.models.generate_content(\n",
        "        model=MODEL,\n",
        "        contents=user_input  # Pass the user input to the model\n",
        "    )\n",
        "    print(f\"Chatbot: {response.text}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QWQw23A597S"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}